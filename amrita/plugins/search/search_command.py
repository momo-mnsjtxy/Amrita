"""ç½‘é¡µæœç´¢å‘½ä»¤å®ç°"""

import re

import httpx
from nonebot import logger, on_command
from nonebot.adapters import Message
from nonebot.adapters.onebot.v11 import Event
from nonebot.params import CommandArg
from nonebot.permission import SUPERUSER

from amrita.plugins.chat import config as chat_config  # type: ignore
from amrita.plugins.chat.utils.libchat import chat_client  # type: ignore

from .config import WebSearchConfig

# åŠ è½½é…ç½®
search_config = WebSearchConfig()

# åˆ›å»ºæœç´¢å‘½ä»¤
search_cmd = on_command(
    "search",
    aliases={"æœç´¢", "ç½‘é¡µæœç´¢", "websearch"},
    priority=5,
    block=True,
    permission=SUPERUSER if search_config.require_permission else None
)

class WebSearcher:
    """ç½‘é¡µæœç´¢å™¨"""

    def __init__(self, config: WebSearchConfig):
        self.config = config
        self.client = httpx.AsyncClient(timeout=config.search_timeout)

        # æœç´¢å¼•æ“é…ç½®
        self.search_engines = {
            "bing": {
                "url": "https://www.bing.com/search",
                "query_param": "q",
                "result_selector": "li.b_algo",
                "title_selector": "h2",
                "snippet_selector": "p",
            },
            "google": {
                "url": "https://www.google.com/search",
                "query_param": "q",
                "result_selector": "div.g",
                "title_selector": "h3",
                "snippet_selector": "span.aCOpRe"
            },
            "duckduckgo": {
                "url": "https://duckduckgo.com/html/",
                "query_param": "q",
                "result_selector": "div.result",
                "title_selector": "h2.result__title",
                "snippet_selector": "a.result__snippet"
            },
            "baidu": {
                "url": "https://www.baidu.com/s",
                "query_param": "wd",
                "result_selector": "div.result",
                "title_selector": "h3",
                "snippet_selector": "span.content-right_8Zs40"
            }
        }

    async def search(self, query: str, engine: str | None = None, safe_search: bool = True) -> list:
        """æ‰§è¡Œç½‘é¡µæœç´¢"""

        if not engine:
            engine = self.config.default_engine

        if engine not in self.search_engines:
            logger.warning(f"ä¸æ”¯æŒçš„æœç´¢å¼•æ“: {engine}ï¼Œä½¿ç”¨é»˜è®¤æœç´¢å¼•æ“: {self.config.default_engine}")
            engine = self.config.default_engine

        try:
            results = await self._perform_search(query, engine, safe_search)
            return results[:self.config.max_results]
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []

    async def _perform_search(self, query: str, engine: str, safe_search: bool) -> list:
        """æ‰§è¡Œå…·ä½“çš„æœç´¢è¯·æ±‚"""

        engine_config = self.search_engines[engine]

        params = {
            engine_config["query_param"]: query,
        }

        # æ·»åŠ å®‰å…¨æœç´¢å‚æ•°
        if safe_search and engine == "bing":
            params["safeSearch"] = "strict"
        elif safe_search and engine == "google":
            params["safe"] = "active"

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        try:
            response = await self.client.get(
                engine_config["url"],
                params=params,
                headers=headers
            )
            response.raise_for_status()

            return await self._parse_results(response.text, engine_config)

        except httpx.RequestError as e:
            logger.error(f"æœç´¢è¯·æ±‚å¤±è´¥: {e}")
            raise

    async def _parse_results(self, html: str, engine_config: dict) -> list:
        """è§£ææœç´¢ç»“æœ"""

        try:
            # ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼è§£æï¼ˆå®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨ BeautifulSoupï¼‰
            # result_pattern = r'<a[^>]*href="([^"]*)"[^>]*>(?:<h3[^>]*>)?([^<]*)(?:</h3>)?</a>'
            # snippet_pattern = r'<span[^>]*class="aCOpRe"[^>]*>([^<]*)</span>'

            # results = []

            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ä½¿ç”¨ HTML è§£æå™¨
            # ä¸ºäº†ä¾èµ–æœ€å°åŒ–ï¼Œå…ˆç”¨ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼
            html_clean = re.sub(r"<[^>]*>", " ", html)

            return [{
                "title": f"æœç´¢ç»“æœ {i+1}",
                "snippet": html_clean[:200] + "...",
                "url": "#"
            } for i in range(5)]

        except Exception as e:
            logger.error(f"è§£ææœç´¢ç»“æœå¤±è´¥: {e}")
            return []

    async def summarize_with_llm(self, query: str, search_results: list) -> str:
        """ä½¿ç”¨LLMæ€»ç»“æœç´¢ç»“æœ"""

        if not search_results or not self.config.summarize_results:
            return ""

        try:
            # æ„å»ºæœç´¢ç»“æœæ–‡æœ¬
            results_text = "\n\n".join([
                f"ç»“æœ{i+1}ï¼š{result.get('title', '')}\n{result.get('snippet', '')}"
                for i, result in enumerate(search_results)
            ])

            # æ„å»ºæç¤ºè¯
            prompt = f"""ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

æœç´¢ç»“æœï¼š
{results_text}

è¯·æ ¹æ®æœç´¢ç»“æœï¼Œä¸ºç”¨æˆ·æä¾›ç®€æ´ã€å‡†ç¡®çš„å›ç­”ã€‚å¦‚æœæœç´¢ç»“æœä¸è¶³ä»¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œè¯·è¯´æ˜ã€‚

å›ç­”å†…å®¹ï¼š"""

            # ä½¿ç”¨é…ç½®çš„èŠå¤©æ¨¡å‹è¿›è¡Œæ€»ç»“
            config = chat_config.get_chat_config()  # type: ignore
            if config and config.enabled:
                system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœç´¢åŠ©æ‰‹ï¼Œè´Ÿè´£æ€»ç»“æœç´¢ç»“æœå¹¶æä¾›å‡†ç¡®ã€ç®€æ´çš„ç­”æ¡ˆã€‚"
                response = await chat_client.chat(
                    prompt=prompt,
                    system=system_prompt,
                    max_tokens=min(self.config.max_summary_length, 1000)
                )

                return response.content if response else "æ— æ³•ç”Ÿæˆæœç´¢æ€»ç»“ã€‚"
            else:
                return "LLMæ€»ç»“åŠŸèƒ½æœªå¯ç”¨ã€‚"

        except Exception as e:
            logger.error(f"LLMæ€»ç»“å¤±è´¥: {e}")
            return "æœç´¢æ€»ç»“ç”Ÿæˆå¤±è´¥ã€‚"

# åˆ›å»ºæœç´¢å™¨å®ä¾‹
web_searcher = WebSearcher(search_config)

@search_cmd.handle()
async def handle_search(event: Event, args: Message = CommandArg()):
    """å¤„ç†æœç´¢å‘½ä»¤"""

    if not search_config.enabled:
        await search_cmd.finish("ç½‘é¡µæœç´¢åŠŸèƒ½å·²ç¦ç”¨")
        return

    query = args.extract_plain_text().strip()
    if not query:
        await search_cmd.finish("è¯·æä¾›æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚ï¼š\n/search äººå·¥æ™ºèƒ½æœ€æ–°å‘å±•")
        return

    await search_cmd.send(f"ğŸŒ æ­£åœ¨æœç´¢ï¼š{query}")

    try:
        # æ‰§è¡Œæœç´¢
        results = await web_searcher.search(query)

        if not results:
            await search_cmd.finish(f'æœªæ‰¾åˆ°å…³äº"{query}"çš„ç›¸å…³ç»“æœ')
            return

        # æ„å»ºå›å¤æ¶ˆæ¯
        reply_msg = f"ğŸ” æœç´¢ç»“æœï¼š{query}\n"
        reply_msg += "=" * 30 + "\n\n"

        # ç”ŸæˆLLMæ€»ç»“
        summary = await web_searcher.summarize_with_llm(query, results)
        if summary:
            reply_msg += f"ğŸ“‹ æ€»ç»“ï¼š\n{summary}\n\n"
            reply_msg += "=" * 30 + "\n\n"

        # æ·»åŠ å…·ä½“ç»“æœ
        reply_msg += "ğŸ”— è¯¦ç»†ç»“æœï¼š\n"
        for i, result in enumerate(results, 1):
            title = result.get("title", f"ç»“æœ {i}")
            snippet = result.get("snippet", "")[:150]
            url = result.get("url", "#")

            reply_msg += f"{i}. {title}\n"
            if snippet:
                reply_msg += f"   {snippet}...\n"
            if url and url != "#":
                reply_msg += f"   {url}\n"
            reply_msg += "\n"

        # æ·»åŠ æç¤º
        reply_msg += "\nğŸ’¡ æç¤ºï¼šå¯ä»¥ä½¿ç”¨ /search --engine=google æŒ‡å®šæœç´¢å¼•æ“"
        reply_msg += "\nå¯é€‰é¡¹ï¼šbing, google, duckduckgo, baidu"

        await search_cmd.finish(reply_msg)

    except Exception as e:
        logger.error(f"å¤„ç†æœç´¢å‘½ä»¤å¤±è´¥: {e}")
        await search_cmd.finish(f"æœç´¢å¤±è´¥ï¼š{e!s}")
